# 关于Dubbo实例异常引发雪崩效应的思考

最近线上出现各种奇奇怪怪的问题,也正是这些问题的出现,让我们对于项目中的设计有了怀疑的想法

是的,没有问题的时候,我们都不太会关注这些

那这一次的雪崩,给我们什么样的紧醒和反思呢?



我们先来看看具体的雪崩情况

## 问题回顾

线上突然多了很多时延和异常告警,以及http服务实例异常

在短短半小时之内http被全量打挂

对dubbo实例进行了紧急的回滚才恢复过来



事后发现http服务在调用rpc的时候会有大量的超时和重试,

一个请求进来,如果要调用几个rpc方法的话,超时的时间几乎达到了十几二十秒

也就是说,我们处理一个请求需要占用一个http的线程十几二十秒

所以在大量请求进来时,服务就顶不住了,引起了雪崩效应



## 反思

有没有想过为什么会产生雪崩效应?

或者换个思路,我们要怎么去做,才能减小雪崩的几率?



我们首先在自己脑海中刻下一句话,每天醒来默念一次: **线程**是非常昂贵的资源

可以发现在这次的问题中,就是因为线程资源不够用了,导致了雪崩



那怎样能够减少线程资源的消耗呢? 让单位时间内能够处理更多的请求



从业务的角度来讲,我们当然希望大部分请求是成功的,哪怕就是它慢了些



先从上面的问题场景入手: 从http服务->rpc服务

假设前提是我们的rpc服务很快,基本上1s内就能够响应成功

突然呢,有一天,我们有百分之十的rpc服务突然变得很慢了,比如需要10s才能响应一个请求

那我们在http服务这边调用rpc的时候,就有百分之十的请求耗时需要升10倍,这样我们大量昂贵的线程资源就被占用了,系统的承压能力瞬间就减少了很多



这里有个问题,就是rpc出现问题的时候,对于http是相对来说无感知的,rpc耗时1s、10s 对http来说,都是正常的



这里面有个非常关键的点,大多数人不太关注的配置: **Dubbo超时时间和重试次数**





